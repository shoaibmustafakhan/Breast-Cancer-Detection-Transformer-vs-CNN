{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":1873742,"datasetId":1115384,"databundleVersionId":1911785}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers       \n!pip install pillow   \n!pip install kagglehub pandas   \n!pip install kaggle      \n!pip install scikit-learn    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:56:37.149218Z","iopub.execute_input":"2025-01-03T14:56:37.149531Z","iopub.status.idle":"2025-01-03T14:56:58.356340Z","shell.execute_reply.started":"2025-01-03T14:56:37.149506Z","shell.execute_reply":"2025-01-03T14:56:58.355126Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\nRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.5)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.66.5)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.8.30)\nRequirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Transformer","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom transformers import AutoImageProcessor, SwinForImageClassification, SwinConfig\nimport PIL.Image\nimport os\nimport pandas as pd\nimport kagglehub\nfrom typing import Tuple, List, Optional\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nfrom pathlib import Path\n\nclass CBISDDSMDataset(Dataset):\n    def __init__(self, base_path: str, split: str = 'train', transform=None, use_roi: bool = True):\n        self.base_path = base_path\n        self.transform = transform\n        self.split = split\n        self.use_roi = use_roi\n        \n        self.data = self._load_and_process_data()\n        self.pathology_to_label = {\n            'BENIGN': 0,\n            'BENIGN_WITHOUT_CALLBACK': 0,\n            'MALIGNANT': 1\n        }\n\n    def _find_valid_image(self, series_uid: str) -> Optional[str]:\n        folder_path = os.path.join(self.base_path, 'jpeg', series_uid)\n        if not os.path.exists(folder_path):\n            return None\n            \n        jpg_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')])\n        if not jpg_files:\n            return None\n            \n        if self.use_roi and len(jpg_files) > 1:\n            return os.path.join(folder_path, jpg_files[1])\n        return os.path.join(folder_path, jpg_files[0])\n\n    def _process_csv(self, csv_path: str, lesion_type: str) -> List[dict]:\n        try:\n            df = pd.read_csv(csv_path)\n            #print(f\"\\nProcessing {lesion_type} CSV\")\n            records = []\n            \n            # Get available image folders\n            jpeg_dir = os.path.join(self.base_path, 'jpeg')\n            available_uids = set(os.listdir(jpeg_dir))\n            \n            for _, row in df.iterrows():\n                try:\n                    # Extract UIDs from path\n                    path = row['cropped image file path'] if self.use_roi else row['image file path']\n                    uids = [p for p in path.split('/') if p.startswith('1.3.6.1.4.1.9590.100.1.2.')]\n                    \n                    # Find matching folder\n                    for uid in uids:\n                        if uid in available_uids:\n                            image_path = self._find_valid_image(uid)\n                            if image_path:\n                                records.append({\n                                    'patient_id': row['patient_id'],\n                                    'image_path': image_path,\n                                    'pathology': row['pathology'],\n                                    'lesion_type': lesion_type,\n                                    'breast_side': row['left or right breast'],\n                                    'view': row['image view'],\n                                    'breast_density': row.get('breast_density', row.get('breast density', None))\n                                })\n                                #print(f\"Match: {uid} -> {row['pathology']}\")\n                                break\n                except Exception as e:\n                    #print(f\"Error processing row: {e}\")\n                    continue\n            \n            #print(f\"Found {len(records)} matches\")\n            return records\n            \n        except Exception as e:\n            #print(f\"Error loading CSV: {str(e)}\")\n            return []\n\n    def _load_and_process_data(self) -> pd.DataFrame:\n        records = []\n        \n        calc_path = os.path.join(self.base_path, 'csv', f'calc_case_description_{self.split}_set.csv')\n        mass_path = os.path.join(self.base_path, 'csv', f'mass_case_description_{self.split}_set.csv')\n        \n        #print(f\"\\nChecking paths:\")\n        #print(f\"Base path: {self.base_path}\")\n        #print(f\"Calc CSV path: {calc_path} (exists: {os.path.exists(calc_path)})\")\n        #print(f\"Mass CSV path: {mass_path} (exists: {os.path.exists(mass_path)})\")\n        \n        #print(\"\\nDirectory contents:\")\n        #for root, dirs, files in os.walk(self.base_path):\n        #    print(f\"\\nDirectory: {root}\")\n        #    if files:\n        #        print(f\"Files: {files}\")\n        \n        if os.path.exists(calc_path):\n            calc_records = self._process_csv(calc_path, 'calc')\n            #print(f\"\\nLoaded {len(calc_records)} calcification records\")\n            records.extend(calc_records)\n        \n        if os.path.exists(mass_path):\n            mass_records = self._process_csv(mass_path, 'mass')\n            #print(f\"\\nLoaded {len(mass_records)} mass records\")\n            records.extend(mass_records)\n            \n        df = pd.DataFrame(records)\n        #if not df.empty:\n        #    print(f\"\\nColumns in DataFrame: {df.columns.tolist()}\")\n            \n        #print(f\"\\nLoaded {len(df)} {self.split} images total\")\n        return df\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int, dict]:\n        row = self.data.iloc[idx]\n        \n        try:\n            image = PIL.Image.open(row['image_path'])\n            if image.mode != 'RGB':\n                image = image.convert('RGB')\n            \n            if self.transform:\n                image = self.transform(image)\n                \n            label = self.pathology_to_label[row['pathology']]\n            \n            metadata = {\n                'patient_id': row['patient_id'],\n                'lesion_type': row['lesion_type'],\n                'breast_side': row['breast_side'],\n                'view': row['view'],\n                'breast_density': row['breast_density']\n            }\n            \n            return image, label, metadata\n            \n        except Exception as e:\n            #print(f\"Error loading {row['image_path']}: {e}\")\n            return self.__getitem__((idx + 1) % len(self))\n\n    def __len__(self) -> int:\n        return len(self.data)\n\ndef create_data_transforms():\n    train_transforms = transforms.Compose([\n        transforms.Resize((384, 384)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.RandomAffine(\n            degrees=0,\n            translate=(0.05, 0.05),\n            scale=(0.95, 1.05)\n        ),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    val_transforms = transforms.Compose([\n        transforms.Resize((384, 384)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    return train_transforms, val_transforms\n\ndef create_model():\n    config = SwinConfig(\n        num_labels=2,\n        image_size=384,\n        patch_size=4,\n        num_channels=3,\n        depths=[2, 2, 18, 2],\n        num_heads=[3, 6, 12, 24],\n        window_size=12,\n        mlp_ratio=4.0,\n        hidden_dropout_prob=0.1,\n        attention_probs_dropout_prob=0.1\n    )\n    return SwinForImageClassification(config)\n\ndef save_checkpoint(epoch, model, optimizer, val_acc, val_f1, is_best=False):\n   checkpoint = {\n       'epoch': epoch,\n       'model_state_dict': model.state_dict(),\n       'optimizer_state_dict': optimizer.state_dict(),\n       'val_acc': val_acc,\n       'val_f1': val_f1\n   }\n   Path('checkpoints').mkdir(exist_ok=True)\n   torch.save(checkpoint, f'checkpoints/checkpoint_epoch_{epoch}.pth')\n   if is_best:\n       torch.save(checkpoint, 'checkpoints/best_model.pth')\n\ndef train_model(model, train_loader, val_loader, device, num_epochs=50):\n   model = model.to(device)\n   start_epoch = 0\n   \n   # Check for existing checkpoints\n   checkpoint_path = Path('checkpoints')\n   if checkpoint_path.exists():\n       checkpoints = list(checkpoint_path.glob('checkpoint_epoch_*.pth'))\n       if checkpoints:\n           latest = max(checkpoints, key=lambda x: int(x.stem.split('_')[-1]))\n           checkpoint = torch.load(latest)\n           model.load_state_dict(checkpoint['model_state_dict'])\n           optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n           optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n           start_epoch = checkpoint['epoch'] + 1\n           best_val_acc = checkpoint['val_acc']\n           best_f1 = checkpoint.get('val_f1', 0)\n       else:\n           optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n           best_val_acc = 0\n           best_f1 = 0\n   else:\n       optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n       best_val_acc = 0\n       best_f1 = 0\n   \n   scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n   criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0]).to(device))\n   \n   early_stopping_patience = 5\n   no_improve_epochs = 0\n   \n   print(\"Starting training...\")\n   \n   for epoch in range(start_epoch, num_epochs):\n       model.train()\n       train_loss = 0\n       train_correct = 0\n       train_total = 0\n       train_preds = []\n       train_labels = []\n       \n       print(f\"\\nStarting epoch {epoch+1}\")\n       \n       for batch_idx, batch in enumerate(train_loader):\n           print(f\"Processing batch {batch_idx}\")\n           try:\n               images, labels, _ = batch\n               print(f\"Batch loaded: images={images.shape}, labels={labels.shape}\")\n               \n               images, labels = images.to(device), labels.to(device)\n               #print(\"Data moved to device\")\n               \n               optimizer.zero_grad()\n               outputs = model(pixel_values=images)\n               #print(\"Forward pass completed\")\n               \n               loss = criterion(outputs.logits, labels)\n               #print(\"Loss calculated\")\n               \n               loss.backward()\n               #print(\"Backward pass completed\")\n               \n               torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n               optimizer.step()\n               #print(\"Optimization step completed\")\n               \n               train_loss += loss.item()\n               _, predicted = outputs.logits.max(1)\n               train_total += labels.size(0)\n               train_correct += predicted.eq(labels).sum().item()\n               \n               train_preds.extend(predicted.cpu().numpy())\n               train_labels.extend(labels.cpu().numpy())\n               \n               if batch_idx % 10 == 0:\n                   print(f'Batch [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f}')\n                   \n           except Exception as e:\n               print(f\"Error in batch {batch_idx}: {str(e)}\")\n               raise e\n               \n       # Evaluate and save checkpoint after each epoch\n       val_acc = evaluate_model(model, val_loader, device)\n       val_f1 = classification_report(train_labels, train_preds, output_dict=True)['weighted avg']['f1-score']\n       \n       is_best = val_acc > best_val_acc\n       if is_best:\n           best_val_acc = val_acc\n           best_f1 = val_f1\n           no_improve_epochs = 0\n       else:\n           no_improve_epochs += 1\n           \n       save_checkpoint(epoch, model, optimizer, val_acc, val_f1, is_best)\n       \n       if no_improve_epochs >= early_stopping_patience:\n           print(f\"Early stopping triggered after {epoch + 1} epochs\")\n           break\n           \n       scheduler.step()\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    test_loss = 0\n    test_correct = 0\n    test_total = 0\n    all_preds = []\n    all_labels = []\n    all_metadata = []\n    \n    criterion = torch.nn.CrossEntropyLoss()\n    \n    with torch.no_grad():\n        for images, labels, metadata in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(pixel_values=images)\n            loss = criterion(outputs.logits, labels)\n            \n            test_loss += loss.item()\n            _, predicted = outputs.logits.max(1)\n            test_total += labels.size(0)\n            test_correct += predicted.eq(labels).sum().item()\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            all_metadata.extend(metadata)\n    \n    test_acc = 100. * test_correct / test_total\n    print(f'\\nTest Accuracy: {test_acc:.2f}%')\n    print('\\nClassification Report:')\n    print(classification_report(all_labels, all_preds, target_names=['Benign', 'Malignant']))\n    print('\\nConfusion Matrix:')\n    print(confusion_matrix(all_labels, all_preds))\n    \n    # Analysis by metadata\n    df = pd.DataFrame({\n        'prediction': all_preds,\n        'true_label': all_labels\n    })\n    \n    #print('\\nPerformance by Lesion Type:')\n    print(classification_report(all_labels, all_preds, target_names=['Benign', 'Malignant']))\n    print('\\nConfusion Matrix:')\n    print(confusion_matrix(all_labels, all_preds))\n    \n    return test_acc\n\ndef main():\n    dataset_path = kagglehub.dataset_download(\n        \"awsaf49/cbis-ddsm-breast-cancer-image-dataset\"\n    )\n    print(f\"Dataset path: {dataset_path}\")\n\n    # Load datasets\n    train_transforms, val_transforms = create_data_transforms()\n    train_dataset = CBISDDSMDataset(dataset_path, 'train', train_transforms, use_roi=True)\n    test_dataset = CBISDDSMDataset(dataset_path, 'test', val_transforms, use_roi=True)\n    \n    if len(train_dataset) == 0 or len(test_dataset) == 0:\n        print(\"Error: Empty dataset\")\n        return\n        \n    # Create train/val split\n    train_size = int(0.9 * len(train_dataset))\n    val_size = len(train_dataset) - train_size\n    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n    \n    # Create dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n    \n    # Set up model and device\n    model = create_model()\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Train\n    train_model(model, train_loader, val_loader, device)\n    \n    # Load best model and evaluate\n    checkpoint = torch.load('checkpoints/best_model.pth')\n    model.load_state_dict(checkpoint['model_state_dict'])\n    print(f\"\\nLoaded best model from epoch {checkpoint['epoch']} \"\n          f\"with validation accuracy {checkpoint['val_acc']:.2f}% \"\n          f\"and F1 score {checkpoint['val_f1']:.2f}\")\n    \n    print(\"\\nEvaluating on test set...\")\n    evaluate_model(model, test_loader, device)\n\nif __name__ == '__main__':\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:16:18.805176Z","iopub.execute_input":"2025-01-03T19:16:18.805506Z","iopub.status.idle":"2025-01-03T19:54:24.959048Z","shell.execute_reply.started":"2025-01-03T19:16:18.805479Z","shell.execute_reply":"2025-01-03T19:54:24.958095Z"}},"outputs":[{"name":"stdout","text":"Dataset path: /kaggle/input/cbis-ddsm-breast-cancer-image-dataset\nUsing device: cuda\nStarting training...\n\nStarting epoch 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.8023\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 1.3135\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.6686\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.8874\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.9795\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.5582\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.8489\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 1.0412\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.5941\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.8363\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.5197\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.8367\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.4873\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.7228\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.5329\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.7148\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.4023\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.6585\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.6556\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.9520\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.5976\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.5874\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 1.1607\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.6398\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.6071\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.5220\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.6037\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.5829\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.5367\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.6229\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.7098\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.7446\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.7774\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 63.76%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.76      0.59      0.67       175\n   Malignant       0.53      0.71      0.60       112\n\n    accuracy                           0.64       287\n   macro avg       0.64      0.65      0.63       287\nweighted avg       0.67      0.64      0.64       287\n\n\nConfusion Matrix:\n[[104  71]\n [ 33  79]]\n              precision    recall  f1-score   support\n\n      Benign       0.76      0.59      0.67       175\n   Malignant       0.53      0.71      0.60       112\n\n    accuracy                           0.64       287\n   macro avg       0.64      0.65      0.63       287\nweighted avg       0.67      0.64      0.64       287\n\n\nConfusion Matrix:\n[[104  71]\n [ 33  79]]\n\nStarting epoch 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 1.1338\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.5462\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.7895\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.4224\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.4696\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.6314\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.6265\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.6610\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 1.0080\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.7341\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.8822\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.6715\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.5261\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.4393\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.6826\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.5865\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.5767\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.7039\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.7726\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.7293\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.7021\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.7395\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.5684\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.9261\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.5639\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.7209\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.8699\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.7336\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.8021\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.6640\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.6671\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.6359\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.9151\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 39.02%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.00      0.00      0.00       175\n   Malignant       0.39      1.00      0.56       112\n\n    accuracy                           0.39       287\n   macro avg       0.20      0.50      0.28       287\nweighted avg       0.15      0.39      0.22       287\n\n\nConfusion Matrix:\n[[  0 175]\n [  0 112]]\n              precision    recall  f1-score   support\n\n      Benign       0.00      0.00      0.00       175\n   Malignant       0.39      1.00      0.56       112\n\n    accuracy                           0.39       287\n   macro avg       0.20      0.50      0.28       287\nweighted avg       0.15      0.39      0.22       287\n\n\nConfusion Matrix:\n[[  0 175]\n [  0 112]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nStarting epoch 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.6306\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.4828\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.7413\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.5394\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.4822\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.5238\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.5895\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.8474\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.6380\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.7387\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.6163\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.6757\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.5968\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.7544\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.7609\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.6632\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.6876\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.7459\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.6533\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.5640\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.6792\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.6333\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.4665\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.5409\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.5503\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.5471\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.5445\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.7082\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.5079\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.6403\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.6236\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.9241\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.5765\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 38.68%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.40      0.01      0.02       175\n   Malignant       0.39      0.97      0.55       112\n\n    accuracy                           0.39       287\n   macro avg       0.39      0.49      0.29       287\nweighted avg       0.39      0.39      0.23       287\n\n\nConfusion Matrix:\n[[  2 173]\n [  3 109]]\n              precision    recall  f1-score   support\n\n      Benign       0.40      0.01      0.02       175\n   Malignant       0.39      0.97      0.55       112\n\n    accuracy                           0.39       287\n   macro avg       0.39      0.49      0.29       287\nweighted avg       0.39      0.39      0.23       287\n\n\nConfusion Matrix:\n[[  2 173]\n [  3 109]]\n\nStarting epoch 4\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.6029\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.8316\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.7504\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.7097\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.6191\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.6391\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.5875\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.6849\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.5570\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.5682\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.6505\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.4638\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.5446\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.6802\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.7004\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.7143\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.6542\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.6916\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.6797\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.5664\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.5118\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.7603\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.7688\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.7108\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.6487\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.6679\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.6610\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.5926\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.7159\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.4012\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.6947\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.6651\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.6083\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 67.60%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.72      0.78      0.75       175\n   Malignant       0.60      0.52      0.56       112\n\n    accuracy                           0.68       287\n   macro avg       0.66      0.65      0.65       287\nweighted avg       0.67      0.68      0.67       287\n\n\nConfusion Matrix:\n[[136  39]\n [ 54  58]]\n              precision    recall  f1-score   support\n\n      Benign       0.72      0.78      0.75       175\n   Malignant       0.60      0.52      0.56       112\n\n    accuracy                           0.68       287\n   macro avg       0.66      0.65      0.65       287\nweighted avg       0.67      0.68      0.67       287\n\n\nConfusion Matrix:\n[[136  39]\n [ 54  58]]\n\nStarting epoch 5\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.8120\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.7170\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.5846\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.8947\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.6344\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 1.1148\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.6684\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.6873\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.6563\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.6029\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.8433\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.6303\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.6185\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.9767\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.4885\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.9289\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.5864\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.6423\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.8539\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.5990\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.6428\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.8714\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.9037\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.5998\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.8124\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.4860\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.7485\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.5342\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.6682\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.5729\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.7716\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.6130\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.7815\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 57.84%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.79      0.42      0.55       175\n   Malignant       0.48      0.82      0.60       112\n\n    accuracy                           0.58       287\n   macro avg       0.63      0.62      0.58       287\nweighted avg       0.67      0.58      0.57       287\n\n\nConfusion Matrix:\n[[ 74 101]\n [ 20  92]]\n              precision    recall  f1-score   support\n\n      Benign       0.79      0.42      0.55       175\n   Malignant       0.48      0.82      0.60       112\n\n    accuracy                           0.58       287\n   macro avg       0.63      0.62      0.58       287\nweighted avg       0.67      0.58      0.57       287\n\n\nConfusion Matrix:\n[[ 74 101]\n [ 20  92]]\n\nStarting epoch 6\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.5103\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.6805\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.5682\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.5160\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.6341\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.7221\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.7547\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.7477\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.7022\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.6157\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.7777\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.6450\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.4293\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.5357\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.5234\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.6932\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.6224\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.5813\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.6458\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.7477\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.6711\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.7792\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.8861\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.6451\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.5968\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.5489\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.4890\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.4512\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.7155\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.8869\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.5938\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.5291\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.7920\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 60.28%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.88      0.41      0.55       175\n   Malignant       0.50      0.91      0.64       112\n\n    accuracy                           0.60       287\n   macro avg       0.69      0.66      0.60       287\nweighted avg       0.73      0.60      0.59       287\n\n\nConfusion Matrix:\n[[ 71 104]\n [ 10 102]]\n              precision    recall  f1-score   support\n\n      Benign       0.88      0.41      0.55       175\n   Malignant       0.50      0.91      0.64       112\n\n    accuracy                           0.60       287\n   macro avg       0.69      0.66      0.60       287\nweighted avg       0.73      0.60      0.59       287\n\n\nConfusion Matrix:\n[[ 71 104]\n [ 10 102]]\n\nStarting epoch 7\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.7422\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.6772\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.6027\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.5103\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.6468\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.6496\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.5685\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.5692\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.5879\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.8514\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.6266\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 1.0100\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.8334\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.5010\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.8525\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.6946\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.5495\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.4655\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.9815\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.4109\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.7027\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.5154\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.8262\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.7476\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.4166\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.7074\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.6649\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.7409\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.5165\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.5145\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.5561\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.7796\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.6238\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 63.76%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.83      0.51      0.63       175\n   Malignant       0.52      0.83      0.64       112\n\n    accuracy                           0.64       287\n   macro avg       0.67      0.67      0.64       287\nweighted avg       0.71      0.64      0.64       287\n\n\nConfusion Matrix:\n[[90 85]\n [19 93]]\n              precision    recall  f1-score   support\n\n      Benign       0.83      0.51      0.63       175\n   Malignant       0.52      0.83      0.64       112\n\n    accuracy                           0.64       287\n   macro avg       0.67      0.67      0.64       287\nweighted avg       0.71      0.64      0.64       287\n\n\nConfusion Matrix:\n[[90 85]\n [19 93]]\n\nStarting epoch 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.5572\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.8123\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.5418\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.5075\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.6063\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.5169\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.5866\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.7498\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.5877\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.7310\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.6316\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.7465\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.6661\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.6699\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.7457\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.5618\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.3975\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.7581\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.6950\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.5105\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.7868\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.8914\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.8296\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.5822\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.5913\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.7010\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.7732\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.8043\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.6369\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.6418\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.7504\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.6812\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.7119\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 54.70%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.88      0.30      0.44       175\n   Malignant       0.46      0.94      0.62       112\n\n    accuracy                           0.55       287\n   macro avg       0.67      0.62      0.53       287\nweighted avg       0.72      0.55      0.51       287\n\n\nConfusion Matrix:\n[[ 52 123]\n [  7 105]]\n              precision    recall  f1-score   support\n\n      Benign       0.88      0.30      0.44       175\n   Malignant       0.46      0.94      0.62       112\n\n    accuracy                           0.55       287\n   macro avg       0.67      0.62      0.53       287\nweighted avg       0.72      0.55      0.51       287\n\n\nConfusion Matrix:\n[[ 52 123]\n [  7 105]]\n\nStarting epoch 9\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 0\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [0/322] Loss: 0.6440\nProcessing batch 1\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 2\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 3\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 4\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 5\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 6\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 7\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 8\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 9\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 10\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [10/322] Loss: 0.6281\nProcessing batch 11\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 12\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 13\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 14\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 15\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 16\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 17\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 18\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 19\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 20\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [20/322] Loss: 0.6449\nProcessing batch 21\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 22\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 23\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 24\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 25\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 26\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 27\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 28\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 29\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 30\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [30/322] Loss: 0.7192\nProcessing batch 31\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 32\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 33\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 34\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 35\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 36\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 37\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 38\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 39\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 40\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [40/322] Loss: 0.5232\nProcessing batch 41\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 42\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 43\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 44\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 45\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 46\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 47\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 48\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 49\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 50\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [50/322] Loss: 0.7085\nProcessing batch 51\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 52\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 53\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 54\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 55\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 56\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 57\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 58\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 59\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 60\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [60/322] Loss: 0.5710\nProcessing batch 61\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 62\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 63\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 64\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 65\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 66\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 67\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 68\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 69\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 70\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [70/322] Loss: 0.9466\nProcessing batch 71\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 72\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 73\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 74\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 75\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 76\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 77\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 78\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 79\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 80\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [80/322] Loss: 0.6950\nProcessing batch 81\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 82\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 83\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 84\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 85\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 86\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 87\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 88\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 89\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 90\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [90/322] Loss: 0.8068\nProcessing batch 91\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 92\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 93\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 94\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 95\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 96\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 97\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 98\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 99\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 100\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [100/322] Loss: 0.7117\nProcessing batch 101\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 102\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 103\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 104\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 105\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 106\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 107\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 108\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 109\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 110\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [110/322] Loss: 0.5391\nProcessing batch 111\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 112\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 113\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 114\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 115\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 116\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 117\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 118\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 119\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 120\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [120/322] Loss: 0.6275\nProcessing batch 121\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 122\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 123\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 124\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 125\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 126\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 127\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 128\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 129\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 130\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [130/322] Loss: 0.5867\nProcessing batch 131\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 132\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 133\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 134\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 135\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 136\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 137\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 138\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 139\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 140\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [140/322] Loss: 0.5989\nProcessing batch 141\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 142\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 143\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 144\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 145\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 146\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 147\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 148\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 149\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 150\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [150/322] Loss: 0.6310\nProcessing batch 151\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 152\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 153\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 154\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 155\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 156\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 157\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 158\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 159\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 160\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [160/322] Loss: 0.5710\nProcessing batch 161\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 162\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 163\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 164\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 165\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 166\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 167\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 168\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 169\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 170\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [170/322] Loss: 0.7292\nProcessing batch 171\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 172\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 173\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 174\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 175\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 176\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 177\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 178\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 179\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 180\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [180/322] Loss: 0.5538\nProcessing batch 181\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 182\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 183\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 184\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 185\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 186\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 187\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 188\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 189\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 190\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [190/322] Loss: 0.7734\nProcessing batch 191\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 192\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 193\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 194\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 195\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 196\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 197\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 198\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 199\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 200\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [200/322] Loss: 0.6719\nProcessing batch 201\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 202\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 203\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 204\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 205\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 206\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 207\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 208\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 209\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 210\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [210/322] Loss: 0.5801\nProcessing batch 211\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 212\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 213\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 214\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 215\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 216\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 217\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 218\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 219\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 220\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [220/322] Loss: 0.6730\nProcessing batch 221\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 222\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 223\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 224\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 225\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 226\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 227\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 228\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 229\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 230\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [230/322] Loss: 0.5563\nProcessing batch 231\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 232\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 233\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 234\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 235\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 236\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 237\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 238\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 239\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 240\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [240/322] Loss: 0.4728\nProcessing batch 241\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 242\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 243\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 244\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 245\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 246\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 247\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 248\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 249\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 250\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [250/322] Loss: 0.6731\nProcessing batch 251\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 252\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 253\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 254\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 255\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 256\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 257\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 258\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 259\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 260\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [260/322] Loss: 0.4866\nProcessing batch 261\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 262\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 263\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 264\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 265\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 266\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 267\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 268\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 269\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 270\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [270/322] Loss: 0.4793\nProcessing batch 271\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 272\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 273\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 274\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 275\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 276\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 277\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 278\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 279\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 280\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [280/322] Loss: 0.6691\nProcessing batch 281\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 282\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 283\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 284\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 285\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 286\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 287\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 288\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 289\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 290\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [290/322] Loss: 0.7446\nProcessing batch 291\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 292\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 293\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 294\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 295\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 296\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 297\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 298\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 299\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 300\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [300/322] Loss: 0.7642\nProcessing batch 301\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 302\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 303\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 304\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 305\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 306\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 307\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 308\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 309\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 310\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [310/322] Loss: 0.6982\nProcessing batch 311\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 312\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 313\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 314\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 315\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 316\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 317\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 318\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 319\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nProcessing batch 320\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\nBatch [320/322] Loss: 0.5338\nProcessing batch 321\nBatch loaded: images=torch.Size([8, 3, 384, 384]), labels=torch.Size([8])\n\nTest Accuracy: 51.57%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.86      0.25      0.38       175\n   Malignant       0.44      0.94      0.60       112\n\n    accuracy                           0.52       287\n   macro avg       0.65      0.59      0.49       287\nweighted avg       0.70      0.52      0.47       287\n\n\nConfusion Matrix:\n[[ 43 132]\n [  7 105]]\n              precision    recall  f1-score   support\n\n      Benign       0.86      0.25      0.38       175\n   Malignant       0.44      0.94      0.60       112\n\n    accuracy                           0.52       287\n   macro avg       0.65      0.59      0.49       287\nweighted avg       0.70      0.52      0.47       287\n\n\nConfusion Matrix:\n[[ 43 132]\n [  7 105]]\nEarly stopping triggered after 9 epochs\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-fd60302a8528>:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('checkpoints/best_model.pth')\n","output_type":"stream"},{"name":"stdout","text":"\nLoaded best model from epoch 3 with validation accuracy 67.60% and F1 score 0.52\n\nEvaluating on test set...\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\nTest Accuracy: 64.35%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.65      0.89      0.75       428\n   Malignant       0.61      0.25      0.36       276\n\n    accuracy                           0.64       704\n   macro avg       0.63      0.57      0.56       704\nweighted avg       0.63      0.64      0.60       704\n\n\nConfusion Matrix:\n[[383  45]\n [206  70]]\n              precision    recall  f1-score   support\n\n      Benign       0.65      0.89      0.75       428\n   Malignant       0.61      0.25      0.36       276\n\n    accuracy                           0.64       704\n   macro avg       0.63      0.57      0.56       704\nweighted avg       0.63      0.64      0.60       704\n\n\nConfusion Matrix:\n[[383  45]\n [206  70]]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"CNN","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom transformers import AutoImageProcessor, SwinForImageClassification, SwinConfig\nimport PIL.Image\nimport os\nimport pandas as pd\nimport kagglehub\nfrom typing import Tuple, List, Optional\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nfrom torchvision import models\n\n\nclass CBISDDSMDataset(Dataset):\n    def __init__(self, base_path: str, split: str = 'train', transform=None, use_roi: bool = True):\n        self.base_path = base_path\n        self.transform = transform\n        self.split = split\n        self.use_roi = use_roi\n        \n        self.data = self._load_and_process_data()\n        self.pathology_to_label = {\n            'BENIGN': 0,\n            'BENIGN_WITHOUT_CALLBACK': 0,\n            'MALIGNANT': 1\n        }\n\n    def _find_valid_image(self, series_uid: str) -> Optional[str]:\n        folder_path = os.path.join(self.base_path, 'jpeg', series_uid)\n        if not os.path.exists(folder_path):\n            return None\n            \n        jpg_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')])\n        if not jpg_files:\n            return None\n            \n        if self.use_roi and len(jpg_files) > 1:\n            return os.path.join(folder_path, jpg_files[1])\n        return os.path.join(folder_path, jpg_files[0])\n\n    def _process_csv(self, csv_path: str, lesion_type: str) -> List[dict]:\n        try:\n            df = pd.read_csv(csv_path)\n            records = []\n            \n            jpeg_dir = os.path.join(self.base_path, 'jpeg')\n            available_uids = set(os.listdir(jpeg_dir))\n            \n            for _, row in df.iterrows():\n                try:\n                    path = row['cropped image file path'] if self.use_roi else row['image file path']\n                    uids = [p for p in path.split('/') if p.startswith('1.3.6.1.4.1.9590.100.1.2.')]\n                    \n                    for uid in uids:\n                        if uid in available_uids:\n                            image_path = self._find_valid_image(uid)\n                            if image_path:\n                                records.append({\n                                    'patient_id': row['patient_id'],\n                                    'image_path': image_path,\n                                    'pathology': row['pathology'],\n                                    'lesion_type': lesion_type,\n                                    'breast_side': row['left or right breast'],\n                                    'view': row['image view'],\n                                    'breast_density': row.get('breast_density', row.get('breast density', None))\n                                })\n                                break\n                except Exception as e:\n                    continue\n            \n            return records\n            \n        except Exception as e:\n            return []\n\n    def _load_and_process_data(self) -> pd.DataFrame:\n        records = []\n        \n        calc_path = os.path.join(self.base_path, 'csv', f'calc_case_description_{self.split}_set.csv')\n        mass_path = os.path.join(self.base_path, 'csv', f'mass_case_description_{self.split}_set.csv')\n        \n        if os.path.exists(calc_path):\n            calc_records = self._process_csv(calc_path, 'calc')\n            records.extend(calc_records)\n        \n        if os.path.exists(mass_path):\n            mass_records = self._process_csv(mass_path, 'mass')\n            records.extend(mass_records)\n            \n        return pd.DataFrame(records)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n        row = self.data.iloc[idx]\n        \n        try:\n            image = PIL.Image.open(row['image_path'])\n            if image.mode != 'RGB':\n                image = image.convert('RGB')\n            \n            if self.transform:\n                image = self.transform(image)\n                \n            label = self.pathology_to_label[row['pathology']]\n            return image, label\n            \n        except Exception as e:\n            return self.__getitem__((idx + 1) % len(self))\n\n    def __len__(self) -> int:\n        return len(self.data)\n\ndef create_data_transforms():\n    train_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    val_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    return train_transforms, val_transforms\n\ndef create_model():\n    model = models.resnet50(pretrained=True)\n    model.fc = torch.nn.Linear(model.fc.in_features, 2)\n    return model\n\ndef train_model(model, train_loader, val_loader, device, num_epochs=20):\n    model = model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n    criterion = torch.nn.CrossEntropyLoss()\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n        train_acc = 100. * correct / total\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    test_acc = 100. * correct / total\n    print(f\"Test Accuracy: {test_acc:.2f}%\")\n    print(\"Classification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=['Benign', 'Malignant']))\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(all_labels, all_preds))\n\ndef main():\n    dataset_path = kagglehub.dataset_download(\"awsaf49/cbis-ddsm-breast-cancer-image-dataset\")\n    print(f\"Dataset path: {dataset_path}\")\n\n    train_transforms, val_transforms = create_data_transforms()\n    train_dataset = CBISDDSMDataset(dataset_path, 'train', train_transforms, use_roi=True)\n    test_dataset = CBISDDSMDataset(dataset_path, 'test', val_transforms, use_roi=True)\n\n    train_size = int(0.9 * len(train_dataset))\n    val_size = len(train_dataset) - train_size\n    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n\n    model = create_model()\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    train_model(model, train_loader, val_loader, device)\n\n    print(\"Evaluating on test set...\")\n    evaluate_model(model, test_loader, device)\n\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:14:37.159406Z","iopub.execute_input":"2025-01-03T21:14:37.159707Z","iopub.status.idle":"2025-01-03T22:16:19.498854Z","shell.execute_reply.started":"2025-01-03T21:14:37.159682Z","shell.execute_reply":"2025-01-03T22:16:19.497961Z"}},"outputs":[{"name":"stdout","text":"Dataset path: /kaggle/input/cbis-ddsm-breast-cancer-image-dataset\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|| 97.8M/97.8M [00:00<00:00, 187MB/s]\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Loss: 105.9569, Accuracy: 60.95%\nEpoch 2/20, Loss: 102.4653, Accuracy: 65.68%\nEpoch 3/20, Loss: 99.4541, Accuracy: 65.30%\nEpoch 4/20, Loss: 98.1801, Accuracy: 66.65%\nEpoch 5/20, Loss: 97.4882, Accuracy: 66.89%\nEpoch 6/20, Loss: 97.9796, Accuracy: 67.55%\nEpoch 7/20, Loss: 95.2418, Accuracy: 67.74%\nEpoch 8/20, Loss: 95.0046, Accuracy: 67.12%\nEpoch 9/20, Loss: 94.5172, Accuracy: 69.25%\nEpoch 10/20, Loss: 94.0299, Accuracy: 69.02%\nEpoch 11/20, Loss: 94.5455, Accuracy: 68.91%\nEpoch 12/20, Loss: 92.4321, Accuracy: 69.84%\nEpoch 13/20, Loss: 89.6415, Accuracy: 71.55%\nEpoch 14/20, Loss: 90.9855, Accuracy: 70.57%\nEpoch 15/20, Loss: 88.5826, Accuracy: 72.24%\nEpoch 16/20, Loss: 89.6815, Accuracy: 71.20%\nEpoch 17/20, Loss: 89.5302, Accuracy: 70.50%\nEpoch 18/20, Loss: 88.1695, Accuracy: 71.35%\nEpoch 19/20, Loss: 88.0538, Accuracy: 71.89%\nEpoch 20/20, Loss: 86.7908, Accuracy: 72.28%\nEvaluating on test set...\nTest Accuracy: 63.64%\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.68      0.75      0.71       428\n   Malignant       0.54      0.46      0.50       276\n\n    accuracy                           0.64       704\n   macro avg       0.61      0.61      0.61       704\nweighted avg       0.63      0.64      0.63       704\n\nConfusion Matrix:\n[[321 107]\n [149 127]]\n","output_type":"stream"}],"execution_count":1}]}